{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Files for Manual Linking\n",
    ">This notebook facilitates writing out non-linked players to an annotation file - then handling the write out to annotation files.  The files can then be loaded here to process: https://j535d165.github.io/recordlinkage-annotator/  Finally the result file can be loaded back into the j_notebook directory where it is picked up here and added to the Record Links database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.index import Block\n",
    "import sqlite3 as sql\n",
    "import functions as fx\n",
    "import core_constants as cc\n",
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class CompareNonExactYears(BaseCompareFeature):\n",
    "\n",
    "    def _compute_vectorized(self, s1, s2):\n",
    "        \"\"\"Compare zipcodes.\n",
    "\n",
    "        If the zipcodes in both records are identical, the similarity\n",
    "        is 0. If the first two values agree and the last two don't, then\n",
    "        the similarity is 0.5. Otherwise, the similarity is 0.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if the zipcode are identical (return 1 or 0)\n",
    "        sim = (((s2 + 3) == s1) | ((s2 + 4) == s1) | ((s2 + 5) == s1)).astype(float)\n",
    "\n",
    "        # check the first 2 numbers of the distinct comparisons\n",
    "        sim[(sim == 0) & (((s1 == (s2 + 2))) | (s1 == (s2 + 6)))] = 0.25\n",
    "\n",
    "        return (sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "> Load the source and target datasets.  Currently it is only written for 247 and Rivals but needs to be extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydatasets = [1,3]\n",
    "dataset_names = []\n",
    "for ds in keydatasets:\n",
    "    SQL = ''' SELECT * FROM DataSet'''\n",
    "    datasets = (fx.connDBAndReturnDF(SQL)).to_dict('records')\n",
    "    dataset = next(item for item in datasets if item[\"KeyDataSet\"] == ds)\n",
    "    SQL = \"\"\"SELECT * FROM {}\"\"\".format(dataset['UnlinkedView'])\n",
    "    \n",
    "    if (ds == 1 or ds == 2):\n",
    "        indexDs = 'IDYR'\n",
    "    else:\n",
    "        indexDs = 'ID'\n",
    "    vars()[dataset['DataSet']] = (fx.connDBAndReturnDF(SQL)).set_index(indexDs)\n",
    "    (vars()[dataset['DataSet']]).index.name = dataset['DataSet'] + indexDs\n",
    "    (vars()[dataset['DataSet']])[indexDs] = (vars()[dataset['DataSet']]).index.get_level_values(0)\n",
    "    dataset_names.append(vars() [dataset['DataSet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = ''' SELECT TargetFieldName FROM Features where KeyMasterDataSet = {} and KeyTargetDataSet = {} and MatchType = \"block\"'''.format(keydatasets[0], keydatasets[1])\n",
    "blockersRaw = (fx.connDBAndReturnDF(SQL)).to_dict('records')\n",
    "blockers = []\n",
    "for i in blockersRaw:\n",
    "    for key,value in i.items():\n",
    "        blockers.append(value)\n",
    "\n",
    "indexer = rl.BlockIndex(on = blockers)\n",
    "candidate_links = indexer.index(dataset_names[1], dataset_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = rl.Compare()\n",
    "\n",
    "SQL = '''SELECT TargetFieldName, MatchType, Method FROM Features where KeyMasterDataSet = {} and KeyTargetDataSet = {} and MatchType <> \"block\"'''.format(keydatasets[0], keydatasets[1])\n",
    "featureFields = (fx.connDBAndReturnDF(SQL).to_dict('records'))\n",
    "\n",
    "for feature in featureFields:\n",
    "    \n",
    "    if (feature['MatchType'] == 'exact'):\n",
    "        c.exact(feature['TargetFieldName'], feature['TargetFieldName'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'string' and feature['Method'] is None):\n",
    "        c.string(feature['TargetFieldName'], feature['TargetFieldName'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'string' and feature['Method'] is not None):\n",
    "        c.string(feature['TargetFieldName'], feature['TargetFieldName'], method = feature['Method'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'numeric' and feature['Method'] is not None):\n",
    "        c.numeric(feature['TargetFieldName'], feature['TargetFieldName'], method = feature['Method'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'custom_year' and feature['Method'] is None):\n",
    "        c.add(CompareNonExactYears(feature['TargetFieldName'], feature['TargetFieldName'], label = feature['TargetFieldName']))\n",
    "try:\n",
    "    features = c.compute(candidate_links, dataset_names[1], dataset_names[0])\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for column in features:\n",
    "    sum = sum + features[column]\n",
    "\n",
    "print(len(featureFields))\n",
    "features['Sum'] = sum/len(featureFields)\n",
    "\n",
    "features.head()\n",
    "\n",
    "features.to_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "filteredList = []\n",
    "noMatch = []\n",
    "\n",
    "features['nfl_ID'] = features.index.get_level_values(0)\n",
    "features['sports247_IDYR'] = features.index.get_level_values(1)\n",
    "\n",
    "\n",
    "for idx, data in features.groupby(level=0):\n",
    "\n",
    "    data = data.loc[data['Sum'].idxmax()]\n",
    "    if (data['ID'] == 1):\n",
    "        filteredList.append(data)\n",
    "    elif (data['ID'] != 1 and data['Sum'] > .1):\n",
    "        filteredList.append(data)\n",
    "    else:\n",
    "        noMatch.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = pd.DataFrame()\n",
    "dfFinal = dfFinal.append(filteredList)\n",
    "dfFinal.head()\n",
    "dfFinal.sort_values(by='Sum', ascending=False)\n",
    "\n",
    "dfFinal.to_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEY ANDREW\n",
    "\n",
    "> Your results are weird because you can't block on a dynamic Year + 5 value before doing a max.  Or at least that's the though.  The number of NFL Draftees, All Americans, etc is much smaller than the overall universe though, so you don't need to be perfect.  Just find something generic that works and knock it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Annotation file\n",
    "> This is actually terrible code.  Currently I'm manually updating by length.  Need to loop through.  TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to look at how this worked before.  You broke something you idiot.\n",
    "length = dfFinal.shape[0]\n",
    "count = 0\n",
    "file_no = 1\n",
    "while (count < length):\n",
    "    rl.write_annotation_file(\n",
    "        \"..//Annotations//Annotations//annotate_NFL\" + str(file_no) + \".json\",\n",
    "        dfFinal[count + 1:count + 500],\n",
    "        dataset_names[1],\n",
    "        dataset_names[0],\n",
    "        dataset_a_name=\"247 Sports\",\n",
    "        dataset_b_name=\"NFLData\")\n",
    "    count = count + 500\n",
    "    file_no = file_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Result\n",
    "> Once you handled the above file in the annotator, the below code will verify that the result file is correctly located in the j_notebooks folder and will read it into a flat index - which makes it easier to insert into the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = rl.read_annotation_file(\"..//Annotations//Results//result_4.json\")\n",
    "try:\n",
    "    annotation_dict = (annotation.links).to_flat_index()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert into the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in annotation_dict:\n",
    "    Values = [record[0], record[1], 2, 1, 1]\n",
    "    query = '''INSERT INTO RecordLinks(MasterID, TargetID, KeyDataSet, KeyLinkType, LinkConfidence)\n",
    "        VALUES (?,?,?,?,?)'''\n",
    "    \n",
    "    conn = sql.connect(cc.databaseName)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(query, Values)\n",
    "    conn.commit()\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
