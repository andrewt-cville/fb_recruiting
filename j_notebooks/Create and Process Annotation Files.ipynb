{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Files for Manual Linking\n",
    ">This notebook facilitates writing out non-linked players to an annotation file - then handling the write out to annotation files.  The files can then be loaded here to process: https://j535d165.github.io/recordlinkage-annotator/  Finally the result file can be loaded back into the j_notebook directory where it is picked up here and added to the Record Links database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.index import Block\n",
    "import sqlite3 as sql\n",
    "import functions as fx\n",
    "import core_constants as cc\n",
    "from recordlinkage.base import BaseCompareFeature\n",
    "\n",
    "class CompareNonExactYears(BaseCompareFeature):\n",
    "\n",
    "    def _compute_vectorized(self, s1, s2):\n",
    "        \"\"\"Compare zipcodes.\n",
    "\n",
    "        If the zipcodes in both records are identical, the similarity\n",
    "        is 0. If the first two values agree and the last two don't, then\n",
    "        the similarity is 0.5. Otherwise, the similarity is 0.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if the zipcode are identical (return 1 or 0)\n",
    "        sim = (((s2 + 3) == s1) | ((s2 + 4) == s1) | ((s2 + 5) == s1)).astype(float)\n",
    "\n",
    "        # check the first 2 numbers of the distinct comparisons\n",
    "        sim[(sim == 0) & ((s1 == (s2 + 2))) & (s1 == (s2 + 6))] = 0.5\n",
    "\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "> Load the source and target datasets.  Currently it is only written for 247 and Rivals but needs to be extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydatasets = [1,3]\n",
    "dataset_names = []\n",
    "for ds in keydatasets:\n",
    "    SQL = ''' SELECT * FROM DataSet'''\n",
    "    datasets = (fx.connDBAndReturnDF(SQL)).to_dict('records')\n",
    "    dataset = next(item for item in datasets if item[\"KeyDataSet\"] == ds)\n",
    "    SQL = \"\"\"SELECT * FROM {}\"\"\".format(dataset['UnlinkedView'])\n",
    "    \n",
    "    if (ds == 1 or ds == 2):\n",
    "        indexDs = 'IDYR'\n",
    "    else:\n",
    "        indexDs = 'ID'\n",
    "    vars()[dataset['DataSet']] = (fx.connDBAndReturnDF(SQL)).set_index(indexDs)\n",
    "    (vars()[dataset['DataSet']]).index.name = dataset['DataSet'] + indexDs\n",
    "    (vars()[dataset['DataSet']])[indexDs] = (vars()[dataset['DataSet']]).index.get_level_values(0)\n",
    "    dataset_names.append(vars() [dataset['DataSet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = ''' SELECT TargetFieldName FROM Features where KeyMasterDataSet = {} and KeyTargetDataSet = {} and MatchType = \"block\"'''.format(keydatasets[0], keydatasets[1])\n",
    "blockersRaw = (fx.connDBAndReturnDF(SQL)).to_dict('records')\n",
    "blockers = []\n",
    "for i in blockersRaw:\n",
    "    for key,value in i.items():\n",
    "        blockers.append(value)\n",
    "\n",
    "indexer = rl.BlockIndex(on = blockers)\n",
    "candidate_links = indexer.index(dataset_names[1], dataset_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = rl.Compare()\n",
    "\n",
    "SQL = '''SELECT TargetFieldName, MatchType, Method FROM Features where KeyMasterDataSet = {} and KeyTargetDataSet = {} and MatchType <> \"block\"'''.format(keydatasets[0], keydatasets[1])\n",
    "featureFields = (fx.connDBAndReturnDF(SQL).to_dict('records'))\n",
    "\n",
    "for feature in featureFields:\n",
    "    \n",
    "    if (feature['MatchType'] == 'exact'):\n",
    "        c.exact(feature['TargetFieldName'], feature['TargetFieldName'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'string' and feature['Method'] is None):\n",
    "        c.string(feature['TargetFieldName'], feature['TargetFieldName'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'string' and feature['Method'] is not None):\n",
    "        c.string(feature['TargetFieldName'], feature['TargetFieldName'], method = feature['Method'], label = feature['TargetFieldName'])\n",
    "    elif(feature['MatchType'] == 'custom_year' and feature['Method'] is None):\n",
    "        c.add(CompareNonExactYears(feature['TargetFieldName'], feature['TargetFieldName'], label = feature['TargetFieldName']))\n",
    "try:\n",
    "    features = c.compute(candidate_links, dataset_names[1], dataset_names[0])\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PlayerName</th>\n",
       "      <th>Position</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLID</th>\n",
       "      <th>Sports247IDYR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">juliuspeppers_northcarolina</th>\n",
       "      <th>tonygrimes_northcarolina_2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desmondevans_northcarolina_2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshdowns_northcarolina_2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mylesmurphy_northcarolina_2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaquriousconley_northcarolina_2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                ID  \\\n",
       "NFLID                       Sports247IDYR                            \n",
       "juliuspeppers_northcarolina tonygrimes_northcarolina_2020        0   \n",
       "                            desmondevans_northcarolina_2020      0   \n",
       "                            joshdowns_northcarolina_2020         0   \n",
       "                            mylesmurphy_northcarolina_2020       0   \n",
       "                            jaquriousconley_northcarolina_2020   0   \n",
       "\n",
       "                                                                PlayerName  \\\n",
       "NFLID                       Sports247IDYR                                    \n",
       "juliuspeppers_northcarolina tonygrimes_northcarolina_2020         0.153846   \n",
       "                            desmondevans_northcarolina_2020       0.153846   \n",
       "                            joshdowns_northcarolina_2020          0.230769   \n",
       "                            mylesmurphy_northcarolina_2020        0.230769   \n",
       "                            jaquriousconley_northcarolina_2020    0.333333   \n",
       "\n",
       "                                                                Position  \\\n",
       "NFLID                       Sports247IDYR                                  \n",
       "juliuspeppers_northcarolina tonygrimes_northcarolina_2020              0   \n",
       "                            desmondevans_northcarolina_2020            0   \n",
       "                            joshdowns_northcarolina_2020               0   \n",
       "                            mylesmurphy_northcarolina_2020             0   \n",
       "                            jaquriousconley_northcarolina_2020         0   \n",
       "\n",
       "                                                                Year       Sum  \n",
       "NFLID                       Sports247IDYR                                       \n",
       "juliuspeppers_northcarolina tonygrimes_northcarolina_2020        0.0  0.038462  \n",
       "                            desmondevans_northcarolina_2020      0.0  0.038462  \n",
       "                            joshdowns_northcarolina_2020         0.0  0.057692  \n",
       "                            mylesmurphy_northcarolina_2020       0.0  0.057692  \n",
       "                            jaquriousconley_northcarolina_2020   0.0  0.083333  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for column in features:\n",
    "    sum = sum + features[column]\n",
    "\n",
    "print(len(featureFields))\n",
    "features['Sum'] = sum/len(featureFields)\n",
    "\n",
    "features.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "filteredList = []\n",
    "noMatch = []\n",
    "\n",
    "features['nfl_ID'] = features.index.get_level_values(0)\n",
    "features['sports247_IDYR'] = features.index.get_level_values(1)\n",
    "\n",
    "\n",
    "for idx, data in features.groupby(level=0):\n",
    "\n",
    "    data = data.loc[data['Sum'].idxmax()]\n",
    "    if (data['ID'] == 1):\n",
    "        filteredList.append(data)\n",
    "    elif (data['ID'] != 1 and data['Sum'] > .1):\n",
    "        filteredList.append(data)\n",
    "    else:\n",
    "        noMatch.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = pd.DataFrame()\n",
    "dfFinal = dfFinal.append(filteredList)\n",
    "dfFinal.head()\n",
    "dfFinal.sort_values(by='Sum', ascending=False)\n",
    "\n",
    "dfFinal.to_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEY ANDREW\n",
    "\n",
    "> Your results are weird because you can't block on a dynamic Year + 5 value before doing a max.  Or at least that's the though.  The number of NFL Draftees, All Americans, etc is much smaller than the overall universe though, so you don't need to be perfect.  Just find something generic that works and knock it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Annotation file\n",
    "> This is actually terrible code.  Currently I'm manually updating by length.  Need to loop through.  TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFinal.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2m/km0nycs128lb7lhq3l_z9cq00000gn/T/ipykernel_54095/1596326070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     rl.write_annotation_file(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"..//Annotations//Annotations//annotate_NFL\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_no\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdfFinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/recordlinkage/annotation.py\u001b[0m in \u001b[0;36mwrite_annotation_file\u001b[0;34m(fp, pairs, df_a, df_b, dataset_a_name, dataset_b_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     annotation_obj = AnnotationWrapper(pairs, df_a, df_b, dataset_a_name,\n\u001b[1;32m     52\u001b[0m                                        dataset_b_name, *args, **kwargs)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mannotation_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/recordlinkage/annotation.py\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/recordlinkage/annotation.py\u001b[0m in \u001b[0;36m_create_annotation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# transform multiindex into frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mdf_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_b\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# dedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "# Need to look at how this worked before.  You broke something you idiot.\n",
    "length = dfFinal.shape[0]\n",
    "count = 0\n",
    "file_no = 1\n",
    "while (count < length):\n",
    "    rl.write_annotation_file(\n",
    "        \"..//Annotations//Annotations//annotate_NFL\" + str(file_no) + \".json\",\n",
    "        dfFinal[count + 1:count + 500],\n",
    "        dataset_names[1],\n",
    "        dataset_names[0],\n",
    "        dataset_a_name=\"247 Sports\",\n",
    "        dataset_b_name=\"NFLData\")\n",
    "    count = count + 500\n",
    "    file_no = file_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Result\n",
    "> Once you handled the above file in the annotator, the below code will verify that the result file is correctly located in the j_notebooks folder and will read it into a flat index - which makes it easier to insert into the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = rl.read_annotation_file(\"..//Annotations//Results//result_4.json\")\n",
    "try:\n",
    "    annotation_dict = (annotation.links).to_flat_index()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert into the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in annotation_dict:\n",
    "    Values = [record[0], record[1], 2, 1, 1]\n",
    "    query = '''INSERT INTO RecordLinks(MasterID, TargetID, KeyDataSet, KeyLinkType, LinkConfidence)\n",
    "        VALUES (?,?,?,?,?)'''\n",
    "    \n",
    "    conn = sql.connect(cc.databaseName)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(query, Values)\n",
    "    conn.commit()\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
