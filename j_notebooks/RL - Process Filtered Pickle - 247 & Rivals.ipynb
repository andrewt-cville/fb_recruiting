{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecordLinkage Linking\n",
    "\n",
    "> Leveraging the RL library to determine approximate matching over a range of fields using various methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "import time\n",
    "import os\n",
    "import recordlinkage\n",
    "import csv\n",
    "import core_constants as cc\n",
    "import functions as fx\n",
    "\n",
    "#not currently using jellyfish\n",
    "import jellyfish as jf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = '..//scrapedData//'\n",
    "field_agg = \"_\"\n",
    "\n",
    "## Load the source file dict\n",
    "sourceFiles = json.loads(open('..//config//sourceFiles.json', \"r\").read())\n",
    "\n",
    "## Load the id config\n",
    "idConfig = json.loads(open('..//config//idConfig.json', \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports247\n",
      "rivals\n",
      "allConf\n",
      "allAmerican\n",
      "nflData\n",
      "ncaa\n"
     ]
    }
   ],
   "source": [
    "## Cycle through all of files per source and drop into a list of dicts\n",
    "## Printing list names for reference sake\n",
    "dfs = []\n",
    "for key in sourceFiles.keys():\n",
    "    vars()[key] = fx.mergeSourceFiles (key, outputDir, sourceFiles)    \n",
    "    dfs.append(vars()[key])\n",
    "    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx.createNewID(idConfig['sports247'], sports247, field_agg)\n",
    "fx.createNewID(idConfig['rivals'], rivals, field_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sports247 = pandas.DataFrame(sports247)\n",
    "df_rivals = pandas.DataFrame(rivals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sports247.index.name = '247_index'\n",
    "df_rivals.index.name = 'rivals_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_id = pandas.read_pickle(\"not_id.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_id.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noIDDict = not_id.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sports247.index.name = '247_index'\n",
    "#df_rivals.index.name = 'rivals_index'\n",
    "df_sports247.reset_index(inplace=True)\n",
    "df_rivals.reset_index(inplace=True)\n",
    "#df_sports247.Index.rename('index', '247_index')\n",
    "#sportDict = df_sports247.to_dict('records')\n",
    "#j=0\n",
    "#for i in sportDict:\n",
    "#    if (j == 0):\n",
    "#        print(i)\n",
    "#    else:\n",
    "#        break\n",
    "#    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hey Sober Andrew - this all works now, but you have to clean-up the output\n",
    "## cause there are dueling column names between the two collections.  \n",
    "## Look at the summarize code to figure out how to handle that\n",
    "\n",
    "sportDict = df_sports247.to_dict('records')\n",
    "rivalsDict = df_rivals.to_dict('records')\n",
    "\n",
    "finalSet = []\n",
    "#print(df_sports247.to_dict('records'))\n",
    "for record in noIDDict:\n",
    "    finalRecord = {}\n",
    "    for recruit in sportDict:\n",
    "        #print(recruit)\n",
    "        if (recruit['247_index'] == record['247_index']):\n",
    "            \n",
    "            for key,value in recruit.items():\n",
    "                finalRecord[key] = value\n",
    "            finalRecord['confidence'] = record['sum']\n",
    "            break\n",
    "    for recruit in rivalsDict:\n",
    "        #print(recruit)\n",
    "        try:\n",
    "            if (recruit['rivals_index'] == record['rivals_index']):\n",
    "                for key,value in recruit.items():\n",
    "                    finalRecord['rivals' + key] = value\n",
    "                break\n",
    "        except:\n",
    "            print(recruit)\n",
    "            print(record)\n",
    "    finalSet.append(finalRecord)\n",
    "print(finalSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReview = pandas.DataFrame(finalSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..//playersForReview.csv\", \"w\", encoding=\"utf-8\") as write_file:\n",
    "                write_file.write(dataReview.to_csv(sep='|', na_rep='N/A', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sports247.head()\n",
    "df_sports247.iloc[5618, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_rivals.iloc[2673, :]\n",
    "test['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.iloc[2673, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_match = []\n",
    "ids = fuzzy_matches['ID']\n",
    "for key in ids.keys():\n",
    "    i = {}\n",
    "    print(key[0])\n",
    "    i['247'] = key[0]\n",
    "    i['rivals'] = key[1]\n",
    "    ids_to_match.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_list = []\n",
    "for i in ids_to_match:\n",
    "    sports247_dict = pandas.DataFrame(df_sports247.iloc[i['247'], :]).to_dict()\n",
    "    \n",
    "    rivals_dict= pandas.DataFrame(df_rivals.iloc[i['rivals'], :]).to_dict()\n",
    "    for i in rivals_dict:   \n",
    "        sports247_dict.update(i)\n",
    "    fuzzy_list.append(sport247_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fuzzy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
